{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "diverse-application",
   "metadata": {},
   "source": [
    "# T5 Model FineTuning #\n",
    "\n",
    "In this notebook, I will be performing finetuning on the T5 Model. In brief, the T5 model is a pre-trained deep learning model that is based on the transformer-architecture. The T5's primary focus of application is in the field of Text-To-Text transformations i.e. Question-Answering, Translation, and Summarization. \n",
    "\n",
    "Our main task in this notebook will be to create a fine-tuned model that will take in an abstract from a research article, and generate a title based on the input information. \n",
    "\n",
    "We will be using a dataset found on kaggle from this link: https://www.kaggle.com/vetrirah/janatahack-independence-day-2020-ml-hackathon?select=train.csv\n",
    "\n",
    "Quoted from the kaggle description:\n",
    "\n",
    "**Topic Modeling for Research Articles\n",
    "Researchers have access to large online archives of scientific articles. As a consequence, finding relevant articles has become more difficult. Tagging or topic modelling provides a way to give token of identification to research articles which facilitates recommendation and search process. Given the abstract and title for a set of research articles, predict the topics for each article included in the test set.**\n",
    "\n",
    "Even though the purpose of the dataset is to predict the topics of the articles, we will only be using it for the primary purpose of fine-tuning our pretrained T5 model to generate a title for each input abstract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incredible-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loc = \"../data/Abstract-Research_Dataset/train.csv\"\n",
    "test_data_loc = \"../data/Abstract-Research_Dataset/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "simple-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import re\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n",
    "from torch.utils.data import random_split, RandomSampler\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import seaborn as sns\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "martial-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "amended-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_loc, encoding='utf-8')\n",
    "test_df = pd.read_csv(test_data_loc, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promotional-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1        Reconstructing Subject-Specific Effect Maps   \n",
       "1   2                 Rotation Invariance Neural Network   \n",
       "2   3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3   4  A finite element approximation for the stochas...   \n",
       "4   5  Comparative study of Discrete Wavelet Transfor...   \n",
       "\n",
       "                                            ABSTRACT  Computer Science  \\\n",
       "0    Predictive models allow subject-specific inf...                 1   \n",
       "1    Rotation invariance and translation invarian...                 1   \n",
       "2    We introduce and develop the notion of spher...                 0   \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "\n",
       "   Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0        0            0           0                     0   \n",
       "1        0            0           0                     0   \n",
       "2        0            1           0                     0   \n",
       "3        0            1           0                     0   \n",
       "4        0            0           1                     0   \n",
       "\n",
       "   Quantitative Finance  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "neural-pizza",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              TITLE  \\\n",
       "0  20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1  20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2  20975         Case For Static AMSDU Aggregation in WLANs   \n",
       "3  20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4  20977  Witness-Functions versus Interpretation-Functi...   \n",
       "\n",
       "                                            ABSTRACT  \n",
       "0    We present novel understandings of the Gamma...  \n",
       "1    Meteorites contain minerals from Solar Syste...  \n",
       "2    Frame aggregation is a mechanism by which mu...  \n",
       "3    Milky Way open clusters are very diverse in ...  \n",
       "4    Proving that a cryptographic protocol is cor...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "generous-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we drop the columns that don't pertain to our task at hand\n",
    "\n",
    "train_df.drop(columns=['ID','Computer Science', 'Physics', 'Mathematics',\n",
    "       'Statistics', 'Quantitative Biology', 'Quantitative Finance'], inplace=True)\n",
    "\n",
    "test_df.drop(columns=['ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-requirement",
   "metadata": {},
   "source": [
    "The first thing I wanted to do was some exploratory data analysis. Primarily finding the distribution of word counts in all of our samples. The reason I do this is that due to memory constraints on my server I may run into an issue of running out of CUDA memory, which would impede my training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "corresponding-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descr: To display plots and metrics regarding token quantity in given input text\n",
    "# Arguements:\n",
    "# =====================================================================\n",
    "# arr1 - input array 1\n",
    "# arr2 - input array 2\n",
    "# show_distr - whether to show plots of distributions\n",
    "# return_distr - whether to return distribution arrays\n",
    "# =====================================================================\n",
    "\n",
    "def DisplayMaxTokens(arr1, arr2, show_distr = False, return_distr = False):\n",
    "    arr1_maxlen = 0\n",
    "    arr2_maxlen = 0\n",
    "    \n",
    "    seq1_LenArr = []\n",
    "    seq2_LenArr = []\n",
    "    \n",
    "    for seq1, seq2 in zip(arr1, arr2):\n",
    "        seq1_text = len(str(seq1).split())\n",
    "        seq2_text = len(str(seq2).split())\n",
    "    \n",
    "        seq1_LenArr.append(seq1_text) \n",
    "        seq2_LenArr.append(seq2_text)    \n",
    "        \n",
    "        if(seq1_text > arr1_maxlen):\n",
    "            arr1_maxlen = seq1_text\n",
    "        if(seq2_text > arr2_maxlen):\n",
    "            arr2_maxlen = seq2_text\n",
    "            \n",
    "    print(\"Maximum number of tokens in Array1: \", arr1_maxlen)\n",
    "    print(\"Maximum number of tokens in Array2: \", arr2_maxlen)\n",
    "    \n",
    "    if(show_distr == True):\n",
    "        sns.displot(seq1_LenArr);\n",
    "        sns.displot(seq2_LenArr);\n",
    "        \n",
    "    if(return_distr == True):\n",
    "        return seq1_LenArr, seq2_LenArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occupational-assistant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of tokens in Array1:  40\n",
      "Maximum number of tokens in Array2:  449\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title_arr = train_df['TITLE']\n",
    "abstract_arr = train_df['ABSTRACT']\n",
    "\n",
    "textlen_Arr, abstractlen_Arr = DisplayMaxTokens(title_arr, abstract_arr, show_distr=True, return_distr = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-deposit",
   "metadata": {},
   "source": [
    "On seeing the above distributions we can see how our word count distribution is. To make sure my machine can handle the memory load I split the dataset such that we only consider the samples where the abstract is less than 200 words. Based on this we split both the training observations and the test observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contained-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['abs_len'] = abstractlen_Arr\n",
    "\n",
    "train_df = train_df[train_df['abs_len'] <= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fallen-necklace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of tokens in Array1:  38\n",
      "Maximum number of tokens in Array2:  391\n"
     ]
    }
   ],
   "source": [
    "title_arr = test_df['TITLE']\n",
    "abstract_arr = test_df['ABSTRACT']\n",
    "\n",
    "textlen_Arr, abstractlen_Arr = DisplayMaxTokens(title_arr, abstract_arr, show_distr=False, return_distr = True)\n",
    "test_df['abs_len'] = abstractlen_Arr\n",
    "\n",
    "test_df = test_df[test_df['abs_len'] <= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "incident-zealand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>abs_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>On the rotation period and shape of the hyperb...</td>\n",
       "      <td>We observed the newly discovered hyperbolic ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "1                 Rotation Invariance Neural Network   \n",
       "2  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3  A finite element approximation for the stochas...   \n",
       "4  Comparative study of Discrete Wavelet Transfor...   \n",
       "6  On the rotation period and shape of the hyperb...   \n",
       "\n",
       "                                            ABSTRACT  abs_len  \n",
       "1    Rotation invariance and translation invarian...       76  \n",
       "2    We introduce and develop the notion of spher...       99  \n",
       "3    The stochastic Landau--Lifshitz--Gilbert (LL...      110  \n",
       "4    Fourier-transform infra-red (FTIR) spectra o...      125  \n",
       "6    We observed the newly discovered hyperbolic ...      105  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.reset_index()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fancy-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>abs_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pairwise Difference Estimation of High Dimensi...</td>\n",
       "      <td>This paper proposes a regularized pairwise d...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  \\\n",
       "0  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2         Case For Static AMSDU Aggregation in WLANs   \n",
       "4  Witness-Functions versus Interpretation-Functi...   \n",
       "5  Pairwise Difference Estimation of High Dimensi...   \n",
       "\n",
       "                                            ABSTRACT  abs_len  \n",
       "0    We present novel understandings of the Gamma...       96  \n",
       "1    Meteorites contain minerals from Solar Syste...      135  \n",
       "2    Frame aggregation is a mechanism by which mu...      126  \n",
       "4    Proving that a cryptographic protocol is cor...      119  \n",
       "5    This paper proposes a regularized pairwise d...      101  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.reset_index()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "generic-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_arr = train_df['TITLE']\n",
    "abstract_arr = train_df['ABSTRACT']\n",
    "\n",
    "title_arr = [re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,\\n]\", '', title) for title in title_arr]\n",
    "abstract_arr = [re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,\\n]\", '', abstract) for abstract in abstract_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-industry",
   "metadata": {},
   "source": [
    "Here we declare our ResearchDataset Class which is inherited from Pytorch's DataSet class. An effective way of preparing and loading data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baking-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descr: Dataset class which is used to load our training data\n",
    "# Constructor Arguements:\n",
    "# =====================================================================\n",
    "# title_arr - Array of article titles\n",
    "# abstract_arr - Array of article abstracts\n",
    "# tokenizer - Input tokenizer used to tokenize our text\n",
    "# =====================================================================\n",
    "\n",
    "class ResearchDataset(Dataset):\n",
    "    def __init__(self, title_arr, abstract_arr, tokenizer):\n",
    "        self.title_arr = title_arr\n",
    "        self.abstract_arr = abstract_arr\n",
    "        self.tokenizer = tokenizer \n",
    "        \n",
    "        def ArrayLength():\n",
    "            title_arr_length = len(self.title_arr)\n",
    "            if(title_arr_length == len(self.abstract_arr)):\n",
    "                return title_arr_length\n",
    "            else:\n",
    "                raise Exception(\"Array Lengths not Equal!!!\")\n",
    "                \n",
    "        self.arr_len = ArrayLength()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.arr_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        title = self.title_arr[index]\n",
    "        abstract = self.abstract_arr[index]\n",
    "        \n",
    "        input_ = abstract + \" </s>\"\n",
    "        output_ = title + \" </s>\"\n",
    "        \n",
    "        #Encoding our inputs\n",
    "        inputs = self.tokenizer.encode_plus(input_, pad_to_max_length=True,return_attention_mask=True, max_length=201)\n",
    "        #Encoding our outputs\n",
    "        outputs = self.tokenizer.encode_plus(output_, pad_to_max_length=True,return_attention_mask=True, max_length=41)\n",
    "        \n",
    "        input_ids = inputs['input_ids']\n",
    "        input_attention_masks = inputs['attention_mask']\n",
    "        \n",
    "        output_ids = outputs['input_ids']\n",
    "        output_attention_masks = outputs['attention_mask']\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'input_mask': torch.tensor(input_attention_masks, dtype=torch.long),\n",
    "            'output_ids': torch.tensor(output_ids, dtype=torch.long),\n",
    "            'output_mask': torch.tensor(output_attention_masks, dtype=torch.long)\n",
    "        }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "increasing-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pre-trained T5-base Tokenizer of T5-base Model\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bearing-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Size:  16807\n",
      "Training Data Size:  16807\n",
      "Validation Data Size:  0\n"
     ]
    }
   ],
   "source": [
    "# Performing splitting of our Dataset in train and validation. Because we were already provided a Validation Dataset, we will not be splitting our train set here, hence our trainset_ratio = 1.0\n",
    "\n",
    "research_dataset = ResearchDataset(title_arr, abstract_arr,tokenizer)\n",
    "\n",
    "trainset_ratio = 1.0\n",
    "\n",
    "data_len = len(research_dataset)\n",
    "print(\"Total Data Size: \", data_len)\n",
    "\n",
    "training_data_size = int(data_len*trainset_ratio)\n",
    "print(\"Training Data Size: \", training_data_size)\n",
    "\n",
    "val_data_size = data_len - training_data_size\n",
    "print(\"Validation Data Size: \", val_data_size)\n",
    "\n",
    "train_dataset, validation_dataset = random_split(research_dataset, [training_data_size, val_data_size])\n",
    "\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size=batch_size)\n",
    "\n",
    "if(trainset_ratio != 1.0):\n",
    "    validation_dataloader = DataLoader(validation_dataset, sampler = RandomSampler(validation_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "destroyed-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/ubuntu/anaconda3/envs/test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/test/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:  0  loss.item:  12.471362113952637\n",
      "EPOCH:  0  loss.item:  1.1752701997756958\n",
      "EPOCH:  0  loss.item:  1.2249319553375244\n"
     ]
    }
   ],
   "source": [
    "# Our actual Process of fine-tuning is done here\n",
    "\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "epochs = 1\n",
    "steps2report = 500\n",
    "\n",
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    model.train()\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting input parameters\n",
    "        x_input_ids = data['input_ids'].to(device)\n",
    "        x_masks = data['input_mask'].to(device)\n",
    "\n",
    "        # Getting output parameters\n",
    "        y_expl_ids = data['output_ids'].to(device)\n",
    "\n",
    "        # Feeding values into our model\n",
    "        outputs = model(input_ids              = x_input_ids, \n",
    "                        attention_mask         = x_masks,\n",
    "                        labels                 = y_expl_ids)\n",
    "        loss = outputs[0] \n",
    "        \n",
    "        if step%steps2report==0:\n",
    "            print(\"EPOCH: \", epoch, \" loss.item: \", loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-rotation",
   "metadata": {},
   "source": [
    "The following column I commented out, but this is the code for saving our fine-tuned model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pacific-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_repository = \"../trained_models/\"\n",
    "#model_name = \"FineTuned_T5_Title_Abstract\"\n",
    "\n",
    "#model.save_pretrained(model_repository+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baking-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "#model = T5ForConditionalGeneration.from_pretrained(\"../trained_models/FineTuned_T5_Title_Abstract\");\n",
    "#model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-sudan",
   "metadata": {},
   "source": [
    "### Validation ###\n",
    "\n",
    "Now that the process of fine-tuning is over, we can now get to the process of validation. We start out by pre-processing our test dataframes and creating our Test-ResearchDataSet and Test-DataLoader. After this we then go through our validation loop where we generate a prediction from each input_id and input_mask, we then store that prediction in model_outputArr, and the expected predictions in target_outputArr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "treated-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_arr = test_df['TITLE']\n",
    "abstract_arr = test_df['ABSTRACT']\n",
    "\n",
    "title_arr = [re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,\\n]\", '', title) for title in title_arr]\n",
    "abstract_arr = [re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,\\n]\", '', abstract) for abstract in abstract_arr]\n",
    "\n",
    "batch_size = 32\n",
    "testresearch_dataset = ResearchDataset(title_arr, abstract_arr, tokenizer)\n",
    "test_dataloader = DataLoader(testresearch_dataset, sampler = RandomSampler(testresearch_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mechanical-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.eval()\n",
    "\n",
    "model_inputArr = []\n",
    "model_outputArr = []\n",
    "target_outputArr = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, data in enumerate(test_dataloader):\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        input_masks = data[\"input_mask\"].to(device)\n",
    "        explanation_ids = data[\"output_ids\"].to(device)\n",
    "        explanation_masks = data[\"output_mask\"].to(device)\n",
    "        output = model.generate(input_ids = input_ids, attention_mask = input_masks, max_length=200,do_sample=False )\n",
    "        \n",
    "        for input_vector, output_vector in zip(input_ids, output):\n",
    "            model_inputArr.append(tokenizer.decode(input_vector, skip_special_tokens=True))\n",
    "            model_outputArr.append(tokenizer.decode(output_vector, skip_special_tokens=True))\n",
    "        target_outputArr.append(tokenizer.batch_decode(explanation_ids, skip_special_tokens=True))    \n",
    "        \n",
    "target_outputArr = [item for sublist in target_outputArr for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "downtown-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe that contains our input, model predicted outout, and expected target output\n",
    "\n",
    "data_ = {\n",
    "    'input' : model_inputArr,\n",
    "    'model output' : model_outputArr,\n",
    "    'target output' : target_outputArr\n",
    "}\n",
    "results_dataframe = pd.DataFrame(data = data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "frank-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>model output</th>\n",
       "      <th>target output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We present an active physical implementation o...</td>\n",
       "      <td>Active physical implementation of the plasmon ...</td>\n",
       "      <td>Active plasmon injection scheme for subdiffrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A plausible mechanism of selfregulation in tec...</td>\n",
       "      <td>Selfregulation in chain of processing</td>\n",
       "      <td>A Bottleneck Principle for TechnoMetabolic Chains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Training generative adversarial networks is un...</td>\n",
       "      <td>Training generative adversarial networks again...</td>\n",
       "      <td>Stabilizing GAN Training with Multiple Random ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This paper enlarges classical syllogistic logi...</td>\n",
       "      <td>A logical system with a syllogistic logic</td>\n",
       "      <td>Syllogistic Logic with Cardinality Comparisons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The excellent electronic and mechanical proper...</td>\n",
       "      <td>Flexible graphene based Hall sensors</td>\n",
       "      <td>Flexible Hall Sensors Based on Graphene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  We present an active physical implementation o...   \n",
       "1  A plausible mechanism of selfregulation in tec...   \n",
       "2  Training generative adversarial networks is un...   \n",
       "3  This paper enlarges classical syllogistic logi...   \n",
       "4  The excellent electronic and mechanical proper...   \n",
       "\n",
       "                                        model output  \\\n",
       "0  Active physical implementation of the plasmon ...   \n",
       "1              Selfregulation in chain of processing   \n",
       "2  Training generative adversarial networks again...   \n",
       "3          A logical system with a syllogistic logic   \n",
       "4               Flexible graphene based Hall sensors   \n",
       "\n",
       "                                       target output  \n",
       "0  Active plasmon injection scheme for subdiffrac...  \n",
       "1  A Bottleneck Principle for TechnoMetabolic Chains  \n",
       "2  Stabilizing GAN Training with Multiple Random ...  \n",
       "3  Syllogistic Logic with Cardinality Comparisons...  \n",
       "4            Flexible Hall Sensors Based on Graphene  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-cooper",
   "metadata": {},
   "source": [
    "### BLEU Evaluation ###\n",
    "\n",
    "Now that we have our predictions, we can evaluate the quality of our predictions based on the Bi-Lingual Evaluation Understudy(BLEU). In brief, we compare our generated sentences with our target sentences by counting the matching n-grams. In layman's terms, how well individual segment texts match from our predicted text to the expected text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "laden-solid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Bleu Score:  0.9615653389238294\n"
     ]
    }
   ],
   "source": [
    "bleu_scores = []\n",
    "\n",
    "for model_output, target_output in zip(model_outputArr, target_outputArr):\n",
    "    model_token_arr = model_output.split();\n",
    "    target_token_arr = model_output.split();\n",
    "\n",
    "    score = sentence_bleu([target_token_arr], model_token_arr)\n",
    "\n",
    "    bleu_scores.append(score)\n",
    "    \n",
    "print(\"Average Bleu Score: \", np.mean(bleu_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
